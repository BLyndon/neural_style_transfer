{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"neural_style_transfer.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"p_zxA7W_LscY","colab_type":"text"},"source":["# Neural Style Transfer with 19-layer VGG-Network\n","\n","**Goal**: Generate a new image G from a base image B with styles from a style image S.\n","\n","\n","## Defining the cost function\n","\n","Minimize a cost function relating G, B and S w.r.t. G\n","$$J(G) = J(G; B, S)$$\n","where B and S are fixed. Further we assume the following form\n","$$J(G;B,S) = \\alpha J(G; B) + \\beta J(G; S)$$ \n","\n","In a ConvNet the shallow layers are activated by small image elements such as edges, whereas the deeper layers are activated by larger structures (see e.g. [Zeiler, Ferges (2013)](https://arxiv.org/abs/1311.2901)). Thus, styles are captured by the activation functions in the middle of ConvNets. \n","\n","In order to enforce similarity between B and G we use MSE as base cost for a deep layer $l$\n","$$J(G; B) = \\frac{1}{2}\\|a^{l}_B - a^l_G\\|$$\n","where $a^l$ is the activation vector of layer $l$.\n","\n","The filter channel activations correspond to the appearance of certain structures and style is composed of several structures. For this reason we want to use the correlation between the filters as a measure for the style cost. \n","\n","The gram matrix is well suited for this task, so we define the style cost as\n","$$J^l(G; S) \\propto \\sum_{k k'} \\left( G_{kk'}^{lS} - G_{kk'}^{lG} \\right)^2$$\n","where\n","$$G^l_{kk'} = \\sum_{ij}^{n_W n_H} a^l_{ijk} a^l_{ijk'}$$\n","\n","Collecting styles from different layers turned out to be more effective, therefore we define the full style cost as weighted sum of different layer style costs\n","$$J(G;S) = \\sum_l J^l(G;S)$$\n","\n","This completes our discussion on the form of the cost function and we turn to the realization."]},{"cell_type":"code","metadata":{"id":"nHBr-Yd-LzPR","colab_type":"code","colab":{}},"source":["import scipy.io\n","import imageio\n","import numpy as np\n","import tensorflow as tf\n","\n","MEANS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n","PATH = '/content/drive/My Drive/Colab Notebooks/NST/'\n","STYLERATIO = 1e-3"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Fg7AeEvEPh3","colab_type":"text"},"source":["## Load 19-VGG model\n","Code from the MathConvNet team. The model can be downloaded [here](http://www.vlfeat.org/matconvnet/pretrained/)."]},{"cell_type":"code","metadata":{"id":"L3xb4x8aENS5","colab_type":"code","colab":{}},"source":["def load_vgg_model(path, shape):\n","    \"\"\"\n","    Detailed configuration of the VGG model:\n","        0 is conv1_1 (3, 3, 3, 64)\n","        1 is relu\n","        2 is conv1_2 (3, 3, 64, 64)\n","        3 is relu    \n","        4 is maxpool\n","        5 is conv2_1 (3, 3, 64, 128)\n","        6 is relu\n","        7 is conv2_2 (3, 3, 128, 128)\n","        8 is relu\n","        9 is maxpool\n","        10 is conv3_1 (3, 3, 128, 256)\n","        11 is relu\n","        12 is conv3_2 (3, 3, 256, 256)\n","        13 is relu\n","        14 is conv3_3 (3, 3, 256, 256)\n","        15 is relu\n","        16 is conv3_4 (3, 3, 256, 256)\n","        17 is relu\n","        18 is maxpool\n","        19 is conv4_1 (3, 3, 256, 512)\n","        20 is relu\n","        21 is conv4_2 (3, 3, 512, 512)\n","        22 is relu\n","        23 is conv4_3 (3, 3, 512, 512)\n","        24 is relu\n","        25 is conv4_4 (3, 3, 512, 512)\n","        26 is relu\n","        27 is maxpool\n","        28 is conv5_1 (3, 3, 512, 512)\n","        29 is relu\n","        30 is conv5_2 (3, 3, 512, 512)\n","        31 is relu\n","        32 is conv5_3 (3, 3, 512, 512)\n","        33 is relu\n","        34 is conv5_4 (3, 3, 512, 512)\n","        35 is relu\n","        36 is maxpool\n","        37 is fullyconnected (7, 7, 512, 4096)\n","        38 is relu\n","        39 is fullyconnected (1, 1, 4096, 4096)\n","        40 is relu\n","        41 is fullyconnected (1, 1, 4096, 1000)\n","        42 is softmax\n","    \"\"\"\n","    \n","    vgg = scipy.io.loadmat(path)\n","\n","    vgg_layers = vgg['layers']\n","    \n","    def _weights(layer, expected_layer_name):\n","        \"\"\"\n","        Return the weights and bias from the VGG model for a given layer.\n","        \"\"\"\n","        wb = vgg_layers[0][layer][0][0][2]\n","        W = wb[0][0]\n","        b = wb[0][1]\n","        layer_name = vgg_layers[0][layer][0][0][0][0]\n","        assert layer_name == expected_layer_name\n","        return W, b\n","\n","    def _relu(conv2d_layer):\n","        \"\"\"\n","        Return the RELU function wrapped over a TensorFlow layer. Expects a\n","        Conv2d layer input.\n","        \"\"\"\n","        return tf.nn.relu(conv2d_layer)\n","\n","    def _conv2d(prev_layer, layer, layer_name):\n","        \"\"\"\n","        Return the Conv2D layer using the weights, biases from the VGG\n","        model at 'layer'.\n","        \"\"\"\n","        W, b = _weights(layer, layer_name)\n","        W = tf.constant(W)\n","        b = tf.constant(np.reshape(b, (b.size)))\n","        return tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n","\n","    def _conv2d_relu(prev_layer, layer, layer_name):\n","        \"\"\"\n","        Return the Conv2D + RELU layer using the weights, biases from the VGG\n","        model at 'layer'.\n","        \"\"\"\n","        return _relu(_conv2d(prev_layer, layer, layer_name))\n","\n","    def _avgpool(prev_layer):\n","        \"\"\"\n","        Return the AveragePooling layer.\n","        \"\"\"\n","        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n","\n","    graph = {}\n","    graph['input']   = tf.Variable(np.zeros((1, shape[0], shape[1], 3)), dtype = 'float32')\n","    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n","    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n","    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n","    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n","    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n","    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n","    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n","    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n","    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n","    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n","    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n","    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n","    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n","    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n","    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n","    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n","    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n","    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n","    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n","    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n","    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n","    \n","    return graph"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DAVnDyoFO47U","colab_type":"text"},"source":["## Helper functions"]},{"cell_type":"code","metadata":{"id":"9fTySaMCPMPj","colab_type":"code","colab":{}},"source":["def save_image(path, image):\n","  image = image + MEANS\n","  image = np.clip(image[0], 0, 255).astype('uint8')\n","  imageio.imsave(path, image, format='png')\n","\n","def show_image(image):\n","  image = image + MEANS\n","  image = np.clip(image[0], 0, 255).astype('uint8')\n","  imshow(image)\n","\n","def noise_image(content_image, noise_ratio = 0.6):\n","  shape = content_image.shape    \n","  noise_image = np.random.uniform(-20, 20, shape).astype('float32')\n","  return noise_image * noise_ratio + content_image * (1 - noise_ratio)\n","\n","def shape_input(image):\n","  image = np.reshape(image, ((1,) + image.shape))\n","  return image - MEANS"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4aAFWN4mIEoD","colab_type":"text"},"source":["## Cost function"]},{"cell_type":"code","metadata":{"id":"0RhBxH-cIGy6","colab_type":"code","colab":{}},"source":["def gram(A):\n","  return tf.matmul(A, tf.transpose(A))\n","\n","def compute_content_cost(a_C, a_G):\n","  _, n_H, n_W, n_C = a_G.get_shape().as_list()\n","  \n","  a_C_flattened = tf.transpose(tf.reshape(a_C, [-1]))\n","  a_G_flattened = tf.transpose(tf.reshape(a_G, [-1]))\n","\n","  return tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled,a_G_unrolled))) / (4 * n_H * n_W * n_C)\n","\n","def layer_style_cost(a_G, a_S):\n","  _, n_H, n_W, n_C = a_G.get_shape().as_list()\n","  \n","  a_G = tf.reshape(tf.transpose(a_G, [n_C, n_W*n_H]))\n","  a_S = tf.reshape(tf.transpose(a_S, [n_C, n_W*n_H]))\n","\n","  G_G = gram(a_G)\n","  G_S = gram(a_S)\n","\n","  return tf.reduce_sum(tf.square(tf.subtract(G_S,G_G)))/(2 * n_C * n_W * n_H)**2\n","\n","def style_cost(model, style_layers):\n","  J_S = 0\n","  for layer, lambd in style_layers:\n","    out = model[layer]\n","    \n","    a_S = sess.run(out)\n","    a_G = out\n","        \n","    J_S_l = layer_style_cost(a_S, a_G)\n","    J_S += lambd * J_S_l\n","\n","  return J_S"],"execution_count":0,"outputs":[]}]}